{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":267.572403,"end_time":"2022-09-19T19:08:41.108432","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-09-19T19:04:13.536029","version":"2.3.4"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906},{"sourceId":10807704,"sourceType":"datasetVersion","datasetId":6708746},{"sourceId":11283424,"sourceType":"datasetVersion","datasetId":7054671},{"sourceId":321918,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":271305,"modelId":292293},{"sourceId":321971,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":271350,"modelId":292337}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nibabel","metadata":{"_uuid":"c2a768e9-0441-4864-a2cd-6c283f88b9a9","_cell_guid":"dd995c2e-5be1-4fe1-8a40-a57fb4a8cfc3","trusted":true,"collapsed":false,"id":"KfHpPR9qHZgZ","outputId":"a8ad19f1-d189-46d4-ebf8-8ce2e4dfed90","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:11:37.123612Z","iopub.execute_input":"2025-05-03T08:11:37.123889Z","iopub.status.idle":"2025-05-03T08:11:41.541989Z","shell.execute_reply.started":"2025-05-03T08:11:37.123867Z","shell.execute_reply":"2025-05-03T08:11:41.540932Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (5.3.2)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel) (5.13.0)\nRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.26.4)\nRequirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.2)\nRequirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22->nibabel) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22->nibabel) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22->nibabel) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22->nibabel) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22->nibabel) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22->nibabel) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22->nibabel) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22->nibabel) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22->nibabel) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22->nibabel) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22->nibabel) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install nilearn","metadata":{"_uuid":"796a5288-165d-462e-97cd-11ddca13ae94","_cell_guid":"94e3df52-3b48-4f9a-bb37-fe5834e77d7d","trusted":true,"collapsed":false,"id":"mjEns0NTHgOb","outputId":"394670ad-d8e9-47ea-8ab5-0255ac3ff1a8","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:11:41.542917Z","iopub.execute_input":"2025-05-03T08:11:41.543160Z","iopub.status.idle":"2025-05-03T08:11:44.824342Z","shell.execute_reply.started":"2025-05-03T08:11:41.543139Z","shell.execute_reply":"2025-05-03T08:11:44.823116Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nilearn in /usr/local/lib/python3.10/dist-packages (0.10.4)\nRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.4.2)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (5.3.0)\nRequirement already satisfied: nibabel>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (5.3.2)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nilearn) (24.2)\nRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.2.3)\nRequirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.32.3)\nRequirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.2.2)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.13.1)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel>=4.0.0->nilearn) (5.13.0)\nRequirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel>=4.0.0->nilearn) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->nilearn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->nilearn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->nilearn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->nilearn) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->nilearn) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->nilearn) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2025.1.31)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.5.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->nilearn) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->nilearn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->nilearn) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->nilearn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->nilearn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->nilearn) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install monai","metadata":{"_uuid":"61250988-e130-4b7c-b41b-d7a475ae6cc5","_cell_guid":"bfdabccc-9b78-42ed-95da-8595b3352ca6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:11:44.825572Z","iopub.execute_input":"2025-05-03T08:11:44.825896Z","iopub.status.idle":"2025-05-03T08:11:49.504029Z","shell.execute_reply.started":"2025-05-03T08:11:44.825871Z","shell.execute_reply":"2025-05-03T08:11:49.503183Z"}},"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.5.1+cu121)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.24->monai) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: monai\nSuccessfully installed monai-1.4.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport time\nfrom random import randint\n\nimport numpy as np\nfrom scipy import stats\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\n\nimport nibabel as nib\nimport nilearn as nl\nimport nilearn.plotting as nlplt\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport matplotlib.animation as anim\nimport matplotlib.patches as mpatches\nimport matplotlib.gridspec as gridspec\n\nfrom IPython.display import Image as show_gif\n\nimport seaborn as sns\nimport imageio\nfrom skimage.transform import resize\nfrom skimage.util import montage\nfrom skimage.transform import rotate\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.nn import MSELoss\n\nimport warnings\nwarnings.simplefilter(\"ignore\")","metadata":{"_uuid":"05ad5de2-c550-4bf3-909e-be8db953b695","_cell_guid":"9e78e278-61b8-45ef-82a6-922a50ad60a4","trusted":true,"collapsed":false,"papermill":{"duration":4.161672,"end_time":"2022-09-19T19:04:25.249138","exception":false,"start_time":"2022-09-19T19:04:21.087466","status":"completed"},"tags":[],"id":"b5be0037","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:11:49.504993Z","iopub.execute_input":"2025-05-03T08:11:49.505251Z","iopub.status.idle":"2025-05-03T08:11:55.836018Z","shell.execute_reply.started":"2025-05-03T08:11:49.505228Z","shell.execute_reply":"2025-05-03T08:11:55.835383Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class GlobalConfig:\n    root_dir = '/kaggle/input/brats20-dataset-training-validation'\n    train_root_dir = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n    test_root_dir = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n    path_to_csv = './train_data.csv'\n\n    seed = 55\n\ndef seed_everything(seed: int):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n\nconfig = GlobalConfig()\nseed_everything(config.seed)","metadata":{"_uuid":"d6bffb54-c744-42f9-9303-a29f4a827130","_cell_guid":"b7ef0c5b-d39b-4021-aba6-40bc16d3006d","trusted":true,"collapsed":false,"papermill":{"duration":0.087063,"end_time":"2022-09-19T19:04:25.404277","exception":false,"start_time":"2022-09-19T19:04:25.317214","status":"completed"},"tags":[],"id":"daa19386","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:11:55.836772Z","iopub.execute_input":"2025-05-03T08:11:55.837235Z","iopub.status.idle":"2025-05-03T08:11:55.896629Z","shell.execute_reply.started":"2025-05-03T08:11:55.837210Z","shell.execute_reply":"2025-05-03T08:11:55.895749Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"survival_info_df = pd.read_csv('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/survival_info.csv')\nname_mapping_df = pd.read_csv('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/name_mapping.csv')\n\nname_mapping_df.rename({'BraTS_2020_subject_ID': 'Brats20ID'}, axis=1, inplace=True)\n\n\ndf = survival_info_df.merge(name_mapping_df, on=\"Brats20ID\", how=\"right\")\n\npaths = []\nfor index, row  in df.iterrows():\n\n    id_ = row['Brats20ID']\n    phase = id_.split(\"_\")[-2]\n\n    if phase == 'Training':\n        path = os.path.join(config.train_root_dir, id_)\n    else:\n        path = os.path.join(config.test_root_dir, id_)\n    paths.append(path)\n\ndf['path'] = paths\n\ntrain_data = df.loc[df['Age'].notnull()].reset_index(drop=True)\ntrain_data = train_data.loc[train_data['Brats20ID'] != 'BraTS20_Training_355'].reset_index(drop=True, ) #eliminam pacientul 355 deoarece formatul nu este bun\n\n# impartim data in antrenare (train), validare (val) si evaluare (test)\nskf = StratifiedKFold(n_splits=7, random_state=config.seed, shuffle=True) #impartim setul de date in 7 parti folosind un seed pentru a obtine mereu aceeasi ordine\nfor i, (train_index, val_index) in enumerate(skf.split(train_data, train_data[\"Age\"]//10*10)):\n        train_data.loc[val_index, \"fold\"] = i\n\ntrain_df = train_data.loc[train_data['fold'] != 0].reset_index(drop=True)\nval_df = train_data.loc[train_data['fold'] == 0].reset_index(drop=True)\n\ntest_df = df.loc[~df['Age'].notnull()].reset_index(drop=True)\nprint(\"train_df ->\", train_df.shape, \"val_df ->\", val_df.shape, \"test_df ->\", test_df.shape)\ntrain_data.to_csv(\"train_data.csv\", index=False)","metadata":{"_uuid":"bb8ccaf0-e790-4137-8938-369c5266bd70","_cell_guid":"0b3e7959-61e5-4b35-8cb5-9fcc0fb30a39","trusted":true,"collapsed":false,"papermill":{"duration":0.120494,"end_time":"2022-09-19T19:04:25.535590","exception":false,"start_time":"2022-09-19T19:04:25.415096","status":"completed"},"tags":[],"id":"009e5146","outputId":"3b3e3d45-1aa6-4f03-bb0e-ee39c95a1b22","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:11:55.899104Z","iopub.execute_input":"2025-05-03T08:11:55.899355Z","iopub.status.idle":"2025-05-03T08:11:55.990421Z","shell.execute_reply.started":"2025-05-03T08:11:55.899335Z","shell.execute_reply":"2025-05-03T08:11:55.989599Z"}},"outputs":[{"name":"stdout","text":"train_df -> (201, 11) val_df -> (34, 11) test_df -> (133, 10)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def load_img1(file_path):\n    data = nib.load(file_path)\n    return data\ntumor_core_total=0\nperitumoral_edema_total=0\nenhancing_tumor_total=0\nnum_zeros_total=0\nfor idx in train_data['Brats20ID']:\n    root_path = train_data.loc[train_data['Brats20ID'] == idx]['path'].values[0] \n    img_path = os.path.join(root_path +'/' + idx+  '_seg.nii')\n    img = load_img1(img_path)\n    a = np.array(img.dataobj)\n    b=a.flatten()\n\n    tumor_core=np.count_nonzero(b == 1)\n    tumor_core_total=tumor_core_total+tumor_core\n\n    peritumoral_edema=np.count_nonzero(b==2)\n    peritumoral_edema_total=peritumoral_edema_total+peritumoral_edema\n\n    enhancing_tumor=np.count_nonzero(b==4)\n    enhancing_tumor_total=enhancing_tumor_total+enhancing_tumor\n\n    num_zeros = (b == 0).sum()\n    num_zeros_total=num_zeros_total+num_zeros\nprint(tumor_core_total)\nprint(peritumoral_edema_total)\nprint(enhancing_tumor_total)\nprint(num_zeros_total)\nprint(tumor_core_total+peritumoral_edema_total+enhancing_tumor_total+num_zeros_total)","metadata":{"_uuid":"372d29f4-9e02-440c-b5db-42b245c1d4f8","_cell_guid":"567ff6f5-8193-45af-a27e-ac6b1ac35337","trusted":true,"collapsed":false,"papermill":{"duration":29.177208,"end_time":"2022-09-19T19:04:54.726236","exception":false,"start_time":"2022-09-19T19:04:25.549028","status":"completed"},"tags":[],"id":"f39c22c7","outputId":"c47ad1d3-a125-4eea-e5e5-c4c751fd8fa6","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:11:55.992162Z","iopub.execute_input":"2025-05-03T08:11:55.992409Z","iopub.status.idle":"2025-05-03T08:12:24.964482Z","shell.execute_reply.started":"2025-05-03T08:11:55.992390Z","shell.execute_reply":"2025-05-03T08:12:24.963553Z"}},"outputs":[{"name":"stdout","text":"2877451\n13244475\n5250041\n2076708033\n2098080000\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def get_center_crop_coords(height, width, depth, crop_height, crop_width, crop_depth):\n                x1 = (height - crop_height) // 2\n                x2 = x1 + crop_height\n                y1 = (width - crop_width) // 2\n                y2 = y1 + crop_width\n                z1 = (depth - crop_depth) // 2\n                z2 = z1 + crop_depth\n                return x1, y1, z1, x2, y2, z2\n\ndef center_crop(data:np.ndarray, crop_height, crop_width, crop_depth):\n    height, width, depth = data.shape[:3]\n    if height < crop_height or width < crop_width or depth < crop_depth:\n        raise ValueError\n    x1, y1, z1, x2, y2, z2 = get_center_crop_coords(height, width, depth, crop_height, crop_width, crop_depth)\n    data = data[x1:x2, y1:y2, z1:z2]\n    return data\n\ndef load_img1(file_path):\n    data = nib.load(file_path)\n    return data\ntumor_core_total=0\nperitumoral_edema_total=0\nenhancing_tumor_total=0\nnum_zeros_total=0\nfor idx in train_data['Brats20ID']:\n    root_path = train_data.loc[train_data['Brats20ID'] == idx]['path'].values[0] \n    img_path = os.path.join(root_path +'/' + idx+  '_seg.nii')\n    img = load_img1(img_path)\n    a = np.array(img.dataobj)\n    get_center_crop_coords(240,240,155, 128,128,128)\n    a=center_crop(a, 128,128,128)\n    b=a.flatten()\n\n    tumor_core=np.count_nonzero(b == 1)\n    tumor_core_total=tumor_core_total+tumor_core\n\n    peritumoral_edema=np.count_nonzero(b==2)\n    peritumoral_edema_total=peritumoral_edema_total+peritumoral_edema\n\n    enhancing_tumor=np.count_nonzero(b==4)\n    enhancing_tumor_total=enhancing_tumor_total+enhancing_tumor\n\n    num_zeros = (b == 0).sum()\n    num_zeros_total=num_zeros_total+num_zeros\nprint(tumor_core_total)\nprint(peritumoral_edema_total)\nprint(enhancing_tumor_total)\nprint(num_zeros_total)\nprint(tumor_core_total+peritumoral_edema_total+enhancing_tumor_total+num_zeros_total)","metadata":{"_uuid":"cfdab61b-a0ab-49d9-ad02-c5e5bae8fdca","_cell_guid":"d91a91a3-4c9a-4a3f-9639-2cc695f6d0c7","trusted":true,"collapsed":false,"papermill":{"duration":3.460199,"end_time":"2022-09-19T19:04:58.194785","exception":false,"start_time":"2022-09-19T19:04:54.734586","status":"completed"},"tags":[],"id":"3a8ac582","outputId":"1d71d215-cb3c-4e2b-e3f2-4bbbac3d4411","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:12:24.965499Z","iopub.execute_input":"2025-05-03T08:12:24.965856Z","iopub.status.idle":"2025-05-03T08:12:28.938229Z","shell.execute_reply.started":"2025-05-03T08:12:24.965824Z","shell.execute_reply":"2025-05-03T08:12:28.937512Z"}},"outputs":[{"name":"stdout","text":"2806199\n12718614\n5020216\n472285691\n492830720\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def load_img1(file_path):\n    data = nib.load(file_path)\n    return data\ntumor_core_total=0\nperitumoral_edema_total=0\nenhancing_tumor_total=0\nnum_zeros_total=0\nfor idx in val_df['Brats20ID']:\n    root_path = val_df.loc[val_df['Brats20ID'] == idx]['path'].values[0] # preluam calea din fisierul csv\n    img_path = os.path.join(root_path +'/' + idx+  '_seg.nii')\n    img = load_img1(img_path)\n    a = np.array(img.dataobj)\n    b=a.flatten()\n#     unique, counts = np.unique(b, return_counts=True)\n#     dict(zip(unique, counts))\n    tumor_core=np.count_nonzero(b == 1)\n    tumor_core_total=tumor_core_total+tumor_core\n\n    peritumoral_edema=np.count_nonzero(b==2)\n    peritumoral_edema_total=peritumoral_edema_total+peritumoral_edema\n\n    enhancing_tumor=np.count_nonzero(b==4)\n    enhancing_tumor_total=enhancing_tumor_total+enhancing_tumor\n\n    num_zeros = (b == 0).sum()\n    num_zeros_total=num_zeros_total+num_zeros\nprint(tumor_core_total)\nprint(peritumoral_edema_total)\nprint(enhancing_tumor_total)\nprint(num_zeros_total)","metadata":{"_uuid":"abc2cd3f-72a7-42f5-a819-e3680ab98569","_cell_guid":"f3333fa7-41d8-45cd-aa5a-6e28d43c3d7c","trusted":true,"collapsed":false,"papermill":{"duration":1.878049,"end_time":"2022-09-19T19:05:00.087272","exception":false,"start_time":"2022-09-19T19:04:58.209223","status":"completed"},"tags":[],"id":"7a7e6dfe","outputId":"003ea68f-ec1c-40e0-9af2-bccec7b09eb0","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:12:28.939185Z","iopub.execute_input":"2025-05-03T08:12:28.939511Z","iopub.status.idle":"2025-05-03T08:12:30.817392Z","shell.execute_reply.started":"2025-05-03T08:12:28.939479Z","shell.execute_reply":"2025-05-03T08:12:30.816476Z"}},"outputs":[{"name":"stdout","text":"472090\n1887772\n814903\n300377235\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from monai.transforms import (\n    Compose,\n    RandAffined,\n    RandGaussianNoised,\n    EnsureChannelFirstd,\n    ScaleIntensityd,\n    RandFlipd,\n    RandRotate90d,\n    ToTensord\n)\n\n# Define MONAI transforms for 3D data\ntrain_transforms = Compose([\n    #EnsureChannelFirstd(keys=['image', 'mask']),  # Ensure data has channel dimension\n    ScaleIntensityd(keys=['image']),  # Normalize intensity values\n    RandAffined(\n        keys=['image', 'mask'],\n        mode=('bilinear', 'nearest'),  # Use bilinear for image, nearest for mask\n        prob=0.5,\n        spatial_size=(128, 128, 128),  # Output size\n        rotate_range=(0, 0, np.pi/15),  # Random rotation\n        scale_range=(0.1, 0.1, 0.1)  # Random scaling\n    ),\n    RandGaussianNoised(keys=['image'], prob=0.5, std=0.01),  # Add Gaussian noise\n    RandFlipd(keys=['image', 'mask'], prob=0.5, spatial_axis=0),  # Random flip\n    RandRotate90d(keys=['image', 'mask'], prob=0.5, max_k=3),  # Random 90-degree rotation\n    ToTensord(keys=['image', 'mask'])  # Convert to PyTorch tensors\n])\n\nclass BratsDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, phase: str=\"test\", transform=None):\n        self.df = df\n        self.phase = phase\n        self.data_types = ['_flair.nii', '_t1.nii', '_t1ce.nii', '_t2.nii']\n        if transform is None:\n            self.transform = train_transforms if phase == \"train\" else Compose([])\n        else:\n            self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        id_ = self.df.loc[idx, 'Brats20ID']\n        root_path = self.df.loc[self.df['Brats20ID'] == id_]['path'].values[0]\n        \n        # Load and preprocess image volumes\n        images = []\n        for data_type in self.data_types:\n            img_path = os.path.join(root_path, id_ + data_type)\n            img = self.load_img(img_path)\n            img = self.center_crop(img, 128, 128, 128)\n            img = self.normalize(img)\n            images.append(img)\n            \n        # Stack modalities to create 4D tensor (4, 128, 128, 128)\n        img = np.stack(images)  # Shape: (4, 128, 128, 128) = (C, H, W, D)\n        img = np.moveaxis(img, (0, 1, 2, 3), (0, 3, 2, 1))\n        img=img.astype(np.float32)\n\n        if self.phase != \"test\":\n            # Load and preprocess mask\n            mask_path = os.path.join(root_path, id_ + \"_seg.nii\")\n            mask = self.load_img(mask_path)\n            mask = self.center_crop(mask, 128, 128, 128)\n            mask = self.preprocess_mask_labels(mask)  # Shape: (3, 128, 128, 128)\n            mask = mask.astype(np.float32)\n            aug_img, aug_mask = img, mask \n\n            # Apply MONAI transforms\n            \n            data = {'image': img, 'mask': mask}\n            transformed = self.transform(data)\n            aug_img = transformed['image']\n            aug_mask = transformed['mask']\n\n            return {\n                \"Id\": id_,\n                \"image\": img,\n                \"mask\": mask,\n                \"aug_image\": aug_img,\n                \"aug_mask\": aug_mask,\n            }\n\n        return {\n            \"Id\": id_,\n            \"image\": torch.from_numpy(img),\n        }\n\n    # Keep other helper methods the same\n    def load_img(self, file_path):\n        data = nib.load(file_path)\n        data = np.asarray(data.dataobj)\n        return data\n\n    def normalize(self, data: np.ndarray):\n        data_min = np.min(data)\n        return (data - data_min) / (np.max(data) - data_min)\n\n    def get_center_crop_coords(self, height, width, depth, crop_height, crop_width, crop_depth):\n        x1 = (height - crop_height) // 2\n        x2 = x1 + crop_height\n        y1 = (width - crop_width) // 2\n        y2 = y1 + crop_width\n        z1 = (depth - crop_depth) // 2\n        z2 = z1 + crop_depth\n        return x1, y1, z1, x2, y2, z2\n\n    def center_crop(self, data: np.ndarray, crop_height, crop_width, crop_depth):\n        height, width, depth = data.shape[:3]\n        if height < crop_height or width < crop_width or depth < crop_depth:\n            raise ValueError\n        x1, y1, z1, x2, y2, z2 = self.get_center_crop_coords(height, width, depth, crop_height, crop_width, crop_depth)\n        data = data[x1:x2, y1:y2, z1:z2]\n        return data\n        \n    def preprocess_mask_labels(self, mask: np.ndarray):\n        mask_WT = mask.copy()\n        mask_WT[mask_WT == 1] = 1  # Label 1 = necrotic / non-enhancing tumor core\n        mask_WT[mask_WT == 2] = 1  # Label 2 = peritumoral edema\n        mask_WT[mask_WT == 4] = 1  # Label 4 = enhancing tumor core\n\n        mask_TC = mask.copy()\n        mask_TC[mask_TC == 1] = 1\n        mask_TC[mask_TC == 2] = 0\n        mask_TC[mask_TC == 4] = 1\n\n        mask_ET = mask.copy()\n        mask_ET[mask_ET == 1] = 0\n        mask_ET[mask_ET == 2] = 0\n        mask_ET[mask_ET == 4] = 1\n\n        mask = np.stack([mask_WT, mask_TC, mask_ET])\n        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))  # Reorder axes for visualization\n        return mask","metadata":{"_uuid":"d0e95b13-a4f3-42e9-babe-a8810d6f473e","_cell_guid":"6084b099-860d-438a-88d0-788ec42ff083","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:12:30.818256Z","iopub.execute_input":"2025-05-03T08:12:30.818531Z","iopub.status.idle":"2025-05-03T08:12:50.596334Z","shell.execute_reply.started":"2025-05-03T08:12:30.818511Z","shell.execute_reply":"2025-05-03T08:12:50.595459Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def get_dataloader(\n    dataset: torch.utils.data.Dataset,\n    path_to_csv: str,\n    phase: str,\n    fold: int = 0,\n    batch_size: int = 1,\n    num_workers: int = 4,\n    transform = None,\n    \n):\n\n    df = pd.read_csv(path_to_csv)\n\n    train_df = df.loc[df['fold'] != fold].reset_index(drop=True)\n    val_df = df.loc[df['fold'] == fold].reset_index(drop=True)\n\n    df = train_df if phase == \"train\" else val_df\n        # Handle dataset splitting\n\n    dataset = dataset(df, phase)\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=True,\n        shuffle=False,\n    )\n    return dataloader\n\n\ntrain_dataloader = get_dataloader(BratsDataset, \"train_data.csv\", phase=\"train\", transform=train_transforms)\nval_dataloader = get_dataloader(BratsDataset, \"train_data.csv\", phase=\"valid\", transform=None, fold = 0)\n","metadata":{"_uuid":"587408e2-f3ab-42b3-8686-a79b5ee82d13","_cell_guid":"89c7987b-2965-4c9d-a771-cfb3cc4f953c","trusted":true,"collapsed":false,"papermill":{"duration":0.030445,"end_time":"2022-09-19T19:05:00.183694","exception":false,"start_time":"2022-09-19T19:05:00.153249","status":"completed"},"tags":[],"id":"0021a54f","outputId":"7dcfb4ee-ca58-4a87-e1a7-dae7882441ed","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:12:50.597096Z","iopub.execute_input":"2025-05-03T08:12:50.597901Z","iopub.status.idle":"2025-05-03T08:12:50.616996Z","shell.execute_reply.started":"2025-05-03T08:12:50.597873Z","shell.execute_reply":"2025-05-03T08:12:50.616073Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"data = next(iter(train_dataloader))\n\n# Print basic info\nprint(\"ID:\", data['Id'])\nprint(\"Original Image Shape:\", data['image'].shape)\nprint(\"Original Mask Shape:\", data['mask'].shape)\nprint(\"Augmented Image Shape:\", data['aug_image'].shape)\nprint(\"Augmented Mask Shape:\", data['aug_mask'].shape)\n\n# Convert masks to numpy for visualization\noriginal_mask = data['mask'].squeeze()[0].cpu().detach().numpy()\naugmented_mask = data['aug_mask'].squeeze()[0].cpu().detach().numpy()\n\n# Print unique values in original and augmented masks\nprint(\"Original Mask Values:\", np.unique(original_mask, return_counts=True))\nprint(\"Augmented Mask Values:\", np.unique(augmented_mask, return_counts=True))\nprint(\"Original Mask Tensor (Slice 60):\", original_mask[60].astype(int))\nprint(\"Augmented Mask Tensor (Slice 60):\", augmented_mask[60].astype(int))","metadata":{"_uuid":"061e7cf1-07ba-44c1-a757-003792a1845d","_cell_guid":"ab247d3c-184f-488f-b941-a2bdd6d0bc1a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:12:50.617794Z","iopub.execute_input":"2025-05-03T08:12:50.618099Z","iopub.status.idle":"2025-05-03T08:12:59.001849Z","shell.execute_reply.started":"2025-05-03T08:12:50.618068Z","shell.execute_reply":"2025-05-03T08:12:59.000863Z"}},"outputs":[{"name":"stdout","text":"ID: ['BraTS20_Training_001']\nOriginal Image Shape: torch.Size([1, 4, 128, 128, 128])\nOriginal Mask Shape: torch.Size([1, 3, 128, 128, 128])\nAugmented Image Shape: torch.Size([1, 4, 128, 128, 128])\nAugmented Mask Shape: torch.Size([1, 3, 128, 128, 128])\nOriginal Mask Values: (array([0., 1.], dtype=float32), array([1886119,  211033]))\nAugmented Mask Values: (array([0., 1.], dtype=float32), array([1851489,  245663]))\nOriginal Mask Tensor (Slice 60): [[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\nAugmented Mask Tensor (Slice 60): [[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import matplotlib.pyplot as plt  \n\nslice_idx = 40  # Choose a relevant slice  \nchannel_idx = 0  # Choose which tumor label to visualize  \n\noriginal_mask = data['mask'][0, channel_idx, :, :, slice_idx].cpu().numpy()  \naugmented_mask = data['aug_mask'][0, channel_idx, :, :, slice_idx].cpu().numpy()  \n\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))  \naxes[0].imshow(original_mask, cmap='gray')  \naxes[0].set_title(\"Original Mask (Channel 0)\")  \naxes[1].imshow(augmented_mask, cmap='gray')  \naxes[1].set_title(\"Augmented Mask (Channel 0)\")  \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T08:12:59.002935Z","iopub.execute_input":"2025-05-03T08:12:59.003270Z","iopub.status.idle":"2025-05-03T08:12:59.387982Z","shell.execute_reply.started":"2025-05-03T08:12:59.003246Z","shell.execute_reply":"2025-05-03T08:12:59.387114Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"def accuracy_coef_metric(probabilities: torch.Tensor,\n                    truth: torch.Tensor,\n                    threshold: float = 0.5, \n                    eps: float = 1e-9) -> np.ndarray:\n    scores = []\n    num = probabilities.shape[0]\n    predictions = (probabilities >= threshold).float()\n    assert predictions.shape == truth.shape\n\n    for i in range(num):\n        prediction = predictions[i]\n        truth_ = truth[i]\n\n        correct = (prediction == truth_).sum().item()\n        total = truth_.numel()\n\n        scores.append(correct / total)\n\n    return np.mean(scores)\n\n\ndef dice_coef_metric(probabilities: torch.Tensor,\n                     truth: torch.Tensor,\n                     treshold: float = 0.5,\n                     eps: float = 1e-9) -> np.ndarray:\n\n    scores = []\n    num = probabilities.shape[0]\n    predictions = (probabilities >= treshold).float()\n    assert(predictions.shape == truth.shape)\n    for i in range(num):\n        prediction = predictions[i]\n        truth_ = truth[i]\n        intersection = 2.0 * (truth_ * prediction).sum()\n        union = truth_.sum() + prediction.sum()\n        if truth_.sum() == 0 and prediction.sum() == 0:\n            scores.append(1.0)\n        else:\n            scores.append((intersection + eps) / union)\n    return np.mean(scores)\n\ndef jaccard_coef_metric(probabilities: torch.Tensor,truth: torch.Tensor, treshold: float = 0.5, eps: float = 1e-9) -> np.ndarray:\n    scores = []\n    num = probabilities.shape[0]\n    predictions = (probabilities >= treshold).float()\n    assert(predictions.shape == truth.shape)\n\n    for i in range(num):\n        prediction = predictions[i]\n        truth_ = truth[i]\n        intersection = (prediction * truth_).sum()\n        union = (prediction.sum() + truth_.sum()) - intersection + eps\n        if truth_.sum() == 0 and prediction.sum() == 0:\n            scores.append(1.0)\n        else:\n            scores.append((intersection + eps) / union)\n    return np.mean(scores)\n\ndef sen_coef_metric(probabilities: np.ndarray,\n                                    truth: np.ndarray,\n                                    treshold: float = 0.5,\n                                    eps: float = 1e-9) -> np.ndarray:\n\n    scores = []\n    num = probabilities.shape[0]\n    predictions = (probabilities >= treshold).float()\n    assert(predictions.shape == truth.shape)\n\n    for i in range(num):\n        prediction = predictions[i]\n        truth_ = truth[i]\n        intersection = (truth_ * prediction).sum()\n        union = truth_.sum()\n        if truth_.sum() == 0 and prediction.sum() == 0:\n                scores.append(1.0)\n        else:\n            scores.append((intersection + eps) / union)\n    return np.mean(scores)\n\n\ndef spf_coef_metric(probabilities: np.ndarray,\n                                    truth: np.ndarray,\n                                    treshold: float = 0.5,\n                                    eps: float = 1e-9) -> np.ndarray:\n\n    scores = []\n    num = probabilities.shape[0]\n    predictions = (probabilities >= treshold).float()\n    assert(predictions.shape == truth.shape)\n\n    for i in range(num):\n        prediction = predictions[i]\n        truth_ = truth[i]\n\n        TN = ((prediction == 0) & (truth_ == 0)).sum().float()  # True Negatives\n        FP = ((prediction == 1) & (truth_ == 0)).sum().float()  # False Positives\n\n        specificity = (TN + eps) / (TN + FP + eps)  # Compute specificity\n        scores.append(specificity.item())  # Convert to Python scalar for numpy compatibility\n\n    return np.mean(scores)  # Return mean specificity as a NumPy scalar\n\n\nclass Meter:\n    # stocam si actualizam dice score-ul\n    def __init__(self, treshold: float = 0.5):\n        self.threshold: float = treshold\n        self.dice_scores: list = []\n        self.iou_scores: list = []\n        self.sen_scores: list=[]\n        self.spf_scores: list=[]\n        self.acc_scores: list = []  # New accuracy list\n\n\n    def update(self, logits: torch.Tensor, targets: torch.Tensor):\n      \n        probs = torch.sigmoid(logits)\n        dice = dice_coef_metric(probs, targets, self.threshold)\n        iou = jaccard_coef_metric(probs, targets, self.threshold)\n        sen = sen_coef_metric(probs, targets, self.threshold)\n        spf = spf_coef_metric(probs, targets, self.threshold)\n        acc = accuracy_coef_metric(probs, targets, self.threshold) \n        self.dice_scores.append(dice)\n        self.iou_scores.append(iou)\n        self.sen_scores.append(sen)\n        self.spf_scores.append(spf)\n        self.acc_scores.append(acc)  \n\n    def get_metrics(self) -> np.ndarray:\n        # returneaza media scorurilor\n        dice = np.mean(self.dice_scores)\n        iou = np.mean(self.iou_scores)\n        sen = np.mean(self.sen_scores)\n        spf = np.mean(self.spf_scores)\n        acc = np.mean(self.acc_scores)  \n        return dice, iou, sen, spf, acc\n\n\nclass DiceLoss(nn.Module):\n    # calculeaza dice loss-ul\n    def __init__(self, eps: float = 1e-9):\n        super(DiceLoss, self).__init__()\n        self.eps = eps\n\n    def forward(self,\n                logits: torch.Tensor,\n                targets: torch.Tensor) -> torch.Tensor:\n\n        num = targets.size(0)\n        probability = torch.sigmoid(logits)\n        probability = probability.view(num, -1)\n        targets = targets.view(num, -1)\n        assert(probability.shape == targets.shape)\n\n        intersection = 2.0 * (probability * targets).sum()\n        union = probability.sum() + targets.sum()\n        dice_score = (intersection + self.eps) / union\n        return 1.0 - dice_score\n\nclass BCEDiceLoss(nn.Module):\n    def __init__(self):\n        super(BCEDiceLoss, self).__init__()\n        self.bce = nn.BCEWithLogitsLoss()\n        self.dice = DiceLoss()\n\n    def forward(self,\n                logits: torch.Tensor,\n                targets: torch.Tensor) -> torch.Tensor:\n        assert(logits.shape == targets.shape)\n        dice_loss = self.dice(logits, targets)\n        bce_loss = self.bce(logits, targets)\n\n        return bce_loss + dice_loss\n\n\ndef dice_coef_metric_per_classes(probabilities: np.ndarray,\n                                    truth: np.ndarray,\n                                    treshold: float = 0.5,\n                                    eps: float = 1e-9,\n                                    classes: list = ['WT', 'TC', 'ET']) -> np.ndarray:\n\n    scores = {key: list() for key in classes}\n    num = probabilities.shape[0]\n    num_classes = probabilities.shape[1]\n    predictions = (probabilities >= treshold).astype(np.float32)\n    assert(predictions.shape == truth.shape)\n\n    for i in range(num):\n        for class_ in range(num_classes):\n            prediction = predictions[i][class_]\n            truth_ = truth[i][class_]\n            intersection = 2.0 * (truth_ * prediction).sum()\n            union = truth_.sum() + prediction.sum()\n            if truth_.sum() == 0 and prediction.sum() == 0:\n                 scores[classes[class_]].append(1.0)\n            else:\n                scores[classes[class_]].append((intersection + eps) / union)\n\n    return scores\n\n\n\ndef sen_coef_metric_per_classes(probabilities: np.ndarray,\n                                    truth: np.ndarray,\n                                    treshold: float = 0.5,\n                                    eps: float = 1e-9,\n                                    classes: list = ['WT', 'TC', 'ET']) -> np.ndarray:\n\n    scores = {key: list() for key in classes}\n    num = probabilities.shape[0]\n    num_classes = probabilities.shape[1]\n    predictions = (probabilities >= treshold)\n    assert(predictions.shape == truth.shape)\n\n    for i in range(num):\n        for class_ in range(num_classes):\n            prediction = predictions[i][class_]\n            truth_ = truth[i][class_]\n            intersection = (truth_ * prediction).sum()\n            union = truth_.sum()\n            if truth_.sum() == 0 and prediction.sum() == 0:\n                 scores[classes[class_]].append(1.0)\n            else:\n                scores[classes[class_]].append((intersection + eps) / union)\n\n    return scores\n\ndef spf_coef_metric_per_classes(probabilities: np.ndarray,\n                                    truth: np.ndarray,\n                                    treshold: float = 0.5,\n                                    eps: float = 1e-9,\n                                    classes: list = ['WT', 'TC', 'ET']) -> np.ndarray:\n\n    scores = {key: list() for key in classes}\n    num = probabilities.shape[0]\n    num_classes = probabilities.shape[1]\n    predictions = (probabilities >= treshold)\n    assert(predictions.shape == truth.shape)\n\n    for i in range(num):\n        for class_ in range(num_classes):\n            prediction = predictions[i][class_]\n            truth_ = truth[i][class_]\n            intersection = (truth_ * prediction).sum()\n            union = prediction.sum()\n            if truth_.sum() == 0 and prediction.sum() == 0:\n                 scores[classes[class_]].append(1.0)\n            else:\n                scores[classes[class_]].append((intersection + eps) / union)\n    return scores\n\ndef jaccard_coef_metric_per_classes(probabilities: np.ndarray,\n               truth: np.ndarray,\n               treshold: float = 0.5,\n               eps: float = 1e-9,\n               classes: list = ['WT', 'TC', 'ET']) -> np.ndarray:\n\n    scores = {key: list() for key in classes}\n    num = probabilities.shape[0]\n    num_classes = probabilities.shape[1]\n    predictions = (probabilities >= treshold).astype(np.float32)\n    assert(predictions.shape == truth.shape)\n\n    for i in range(num):\n        for class_ in range(num_classes):\n            prediction = predictions[i][class_]\n            truth_ = truth[i][class_]\n            intersection = (prediction * truth_).sum()\n            union = (prediction.sum() + truth_.sum()) - intersection + eps\n            if truth_.sum() == 0 and prediction.sum() == 0:\n                 scores[classes[class_]].append(1.0)\n            else:\n                scores[classes[class_]].append((intersection + eps) / union)\n\n    return scores","metadata":{"_uuid":"0409db88-3d55-430a-99a8-f233006d0e23","_cell_guid":"e15d1042-baee-4c8e-9254-0dd34027dac0","trusted":true,"collapsed":false,"papermill":{"duration":0.063739,"end_time":"2022-09-19T19:05:08.013901","exception":false,"start_time":"2022-09-19T19:05:07.950162","status":"completed"},"tags":[],"id":"f679e307","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:12:59.388752Z","iopub.execute_input":"2025-05-03T08:12:59.388974Z","iopub.status.idle":"2025-05-03T08:12:59.415578Z","shell.execute_reply.started":"2025-05-03T08:12:59.388948Z","shell.execute_reply":"2025-05-03T08:12:59.414740Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"IR-ViT-MSF","metadata":{"_uuid":"7044aaed-7974-4f45-8352-093ce5bf333e","_cell_guid":"01c7623d-7fc2-4c5c-a772-725bc230b6ac","trusted":true,"collapsed":false,"papermill":{"duration":0.007941,"end_time":"2022-09-19T19:05:08.238801","exception":false,"start_time":"2022-09-19T19:05:08.230860","status":"completed"},"tags":[],"id":"b219b8a2","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops.layers.torch import Rearrange\nfrom torch.cuda.amp import autocast\n\n# 3D Inception-Residual Block\nclass InceptionResBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv1x1 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=1, padding=0)\n        self.conv3x3 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=3, padding=1)\n        self.conv5x5 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=5, padding=2)\n        self.conv7x7 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=7, padding=3)\n        self.residual = nn.Conv3d(in_channels, out_channels, kernel_size=1, padding=0)\n        self.bn = nn.InstanceNorm3d(out_channels)\n\n    def forward(self, x):\n        out = torch.cat([self.conv1x1(x), self.conv3x3(x), self.conv5x5(x), self.conv7x7(x)], dim=1)\n        out = self.bn(out + self.residual(x))\n        return F.relu(out)\n\n# 3D Vision Transformer Encoder Block\nclass ViTBlock(nn.Module):\n    def __init__(self, dim, num_heads):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(dim)\n        self.attn = nn.MultiheadAttention(dim, num_heads)\n        self.norm2 = nn.LayerNorm(dim)\n        self.mlp = nn.Sequential(\n            nn.Linear(dim, dim * 4),\n            nn.GELU(),\n            nn.Linear(dim * 4, dim)\n        )\n\n    def forward(self, x):\n        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n        x = x + self.mlp(self.norm2(x))\n        return x\n\n# Multi-Scale Fusion Module\nclass MultiScaleFusion(nn.Module):\n    def __init__(self, in_channels, skip_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Conv3d(in_channels + skip_channels, out_channels, kernel_size=3, padding=1)\n        self.up = nn.ConvTranspose3d(in_channels, in_channels, kernel_size=2, stride=2)\n\n    def forward(self, x, skip):\n        x = self.up(x)\n        x = torch.cat([x, skip], dim=1)\n        return F.relu(self.conv(x))\n\n# The Hybrid ViT-CNN-PCR Model\nclass ViT_CNN_Segmentation(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # Encoder\n        self.enc1 = InceptionResBlock(4, 32)\n        self.enc2 = InceptionResBlock(32, 64)\n        self.enc3 = InceptionResBlock(64, 128)\n        self.enc4 = InceptionResBlock(128, 128)  # Adjusted to 128 channels\n        \n        # Transformer Bottleneck\n        self.flatten = Rearrange('b c d h w -> b (d h w) c')\n        self.vit = ViTBlock(128, num_heads=8)\n        self.unflatten = Rearrange('b (d h w) c -> b c d h w', d=16, h=16, w=16)\n        \n        # Decoder\n        self.dec3 = MultiScaleFusion(128, 128, 128)\n        self.dec2 = MultiScaleFusion(128, 64, 64)\n        self.dec1 = MultiScaleFusion(64, 32, 32)\n        \n        # Output layer\n        self.out_conv = nn.Conv3d(32, 3, kernel_size=1)\n\n    def forward(self, x):\n        # Encoding\n        x1 = self.enc1(x)\n        x2 = self.enc2(F.max_pool3d(x1, 2))\n        x3 = self.enc3(F.max_pool3d(x2, 2))\n        x4 = self.enc4(F.max_pool3d(x3, 2))\n        \n        # Transformer\n        vit_features = self.vit(self.flatten(x4))\n        vit_features = self.unflatten(vit_features)\n        \n        # Decoding\n        x = self.dec3(vit_features, x3)\n        x = self.dec2(x, x2)\n        x = self.dec1(x, x1)\n        \n        return self.out_conv(x)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T08:12:59.416478Z","iopub.execute_input":"2025-05-03T08:12:59.416763Z","iopub.status.idle":"2025-05-03T08:12:59.445095Z","shell.execute_reply.started":"2025-05-03T08:12:59.416743Z","shell.execute_reply":"2025-05-03T08:12:59.444264Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"!pip install seaborn","metadata":{"_uuid":"07266844-3b3d-4f38-a138-00ca849dc6b5","_cell_guid":"efc84ca5-574f-465e-b151-b92c73da39db","trusted":true,"collapsed":false,"id":"8rTXulBZM8Jx","outputId":"8865cc94-9102-41f1-8907-bc8aa8671eac","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:12:59.445991Z","iopub.execute_input":"2025-05-03T08:12:59.446187Z","iopub.status.idle":"2025-05-03T08:13:02.901116Z","shell.execute_reply.started":"2025-05-03T08:12:59.446170Z","shell.execute_reply":"2025-05-03T08:13:02.900262Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy!=1.24.0,>=1.17->seaborn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nprint(plt.style.available)","metadata":{"_uuid":"5739bbd3-50f0-44a2-990e-554eea11aefa","_cell_guid":"330d2151-df4a-4673-8dd9-8de700da9996","trusted":true,"collapsed":false,"id":"QIqsiJYvQCpA","outputId":"5fb22861-da06-4b61-ba87-d1c81ef483b0","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:13:02.902245Z","iopub.execute_input":"2025-05-03T08:13:02.902606Z","iopub.status.idle":"2025-05-03T08:13:02.906982Z","shell.execute_reply.started":"2025-05-03T08:13:02.902581Z","shell.execute_reply":"2025-05-03T08:13:02.906346Z"}},"outputs":[{"name":"stdout","text":"['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import seaborn as sns\nclass Trainer:\n    def __init__(self,\n                 net: nn.Module,\n                 dataset: torch.utils.data.Dataset,\n                 criterion: nn.Module,\n                 lr: float,\n                 accumulation_steps: int,\n                 batch_size: int,\n                 fold: int,\n                 num_epochs: int,\n                 path_to_csv: str,\n                 display_plot: bool = True,\n                ):\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        print(\"device:\", self.device)\n        self.display_plot = display_plot\n        self.net = net.to(self.device)\n        self.criterion = criterion\n        self.optimizer = Adam(self.net.parameters(), lr=lr)\n        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=4, verbose=True)\n        self.accumulation_steps = accumulation_steps // batch_size\n        self.phases = [\"train\", \"val\"]\n        self.num_epochs = num_epochs\n\n        # Initialize fresh dataloaders\n        self.dataloaders = {\n            phase: get_dataloader(\n                dataset=dataset,\n                path_to_csv=path_to_csv,\n                phase=phase,\n                fold=fold,\n                batch_size=batch_size,\n                num_workers=4,\n                #augment_prob= 0.1,  # Probability of applying augmentations\n            )\n            for phase in self.phases\n        }\n\n        # Ensure fresh training: Reset best loss and training logs\n        self.best_loss = float(\"inf\")\n        self.losses = {phase: [] for phase in self.phases}\n        self.dice_scores = {phase: [] for phase in self.phases}\n        self.jaccard_scores = {phase: [] for phase in self.phases}\n        self.sen_scores = {phase: [] for phase in self.phases}\n        self.spf_scores = {phase: [] for phase in self.phases}\n        self.acc_scores = {phase: [] for phase in self.phases}\n\n    def _compute_loss_and_outputs(self, images: torch.Tensor, targets: torch.Tensor):\n        images, targets = images.to(self.device), targets.to(self.device)\n        logits = self.net(images)\n        loss = self.criterion(logits, targets)\n        return loss, logits\n\n    def _do_epoch(self, epoch: int, phase: str):\n        print(f\"{phase} epoch: {epoch} | time: {time.strftime('%H:%M:%S')}\")\n        self.net.train() if phase == \"train\" else self.net.eval()\n        meter = Meter()\n        dataloader = self.dataloaders[phase]\n        total_batches = len(dataloader)\n        running_loss = 0.0\n        self.optimizer.zero_grad()\n\n       # Progress bar using tqdm\n        with tqdm(total=total_batches, desc=f\"{phase.upper()} {epoch+1}\", unit=\"batch\") as pbar:\n            for itr, data_batch in enumerate(dataloader):\n                images, targets = data_batch['image'], data_batch['mask']\n                loss, logits = self._compute_loss_and_outputs(images, targets)\n                loss = loss / self.accumulation_steps\n\n                if phase == \"train\":\n                    loss.backward()\n                    if (itr + 1) % self.accumulation_steps == 0:\n                        self.optimizer.step()\n                        self.optimizer.zero_grad()\n\n                running_loss += loss.item()\n                meter.update(logits.detach().cpu(), targets.detach().cpu())\n\n                # Update progress bar with loss\n                pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n                pbar.update(1)\n\n        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n        epoch_dice, epoch_iou, epoch_sen, epoch_spf, epoch_acc = meter.get_metrics()\n\n        self.losses[phase].append(epoch_loss)\n        self.dice_scores[phase].append(epoch_dice)\n        self.jaccard_scores[phase].append(epoch_iou)\n        self.sen_scores[phase].append(epoch_sen)\n        self.spf_scores[phase].append(epoch_spf)\n        self.acc_scores[phase].append(epoch_acc)\n\n        return epoch_loss\n\n    def run(self):\n        print(\"Starting training from scratch...\")\n\n        for epoch in range(self.num_epochs):\n            self._do_epoch(epoch, \"train\")\n            with torch.no_grad():\n                val_loss = self._do_epoch(epoch, \"val\")\n                self.scheduler.step(val_loss)\n\n            # Save best model\n            if val_loss < self.best_loss:\n                print(f\"\\n{'#' * 20}\\nSaved new checkpoint\\n{'#' * 20}\\n\")\n                self.best_loss = val_loss\n                torch.save(self.net.state_dict(), \"best_model.pth\")\n\n            print()\n        \n        if self.display_plot:\n            self._plot_train_history()\n\n        self._save_train_history()\n\n    def _plot_train_history(self):\n        data = [self.losses, self.dice_scores, self.jaccard_scores, self.acc_scores, self.sen_scores, self.spf_scores]\n        colors = ['deepskyblue', \"crimson\"]\n        labels = [\n            f\"\"\"\n            train loss {self.losses['train'][-1]}\n            val loss {self.losses['val'][-1]}\n            \"\"\",\n\n            f\"\"\"\n            train dice score {self.dice_scores['train'][-1]}\n            val dice score {self.dice_scores['val'][-1]}\n            \"\"\",\n\n            f\"\"\"\n            train jaccard score {self.jaccard_scores['train'][-1]}\n            val jaccard score {self.jaccard_scores['val'][-1]}\n            \"\"\",\n\n            f\"\"\"\n            train acc score {self.acc_scores['train'][-1]}\n            val acc score {self.acc_scores['val'][-1]}\n            \"\"\",\n\n            f\"\"\"\n            train sen score {self.sen_scores['train'][-1]}\n            val sen score {self.sen_scores['val'][-1]}\n            \"\"\",\n\n            f\"\"\"\n            train spf score {self.spf_scores['train'][-1]}\n            val spf score {self.spf_scores['val'][-1]}\n            \"\"\",\n        ]\n\n        with plt.style.context(\"seaborn-dark-palette\"):\n        # Dynamically calculate the number of rows and columns\n            num_plots = len(data)\n            num_cols = 3  # Number of columns\n            num_rows = (num_plots + num_cols - 1) // num_cols  # Calculate rows dynamically\n\n            # Create subplots\n            fig, axes = plt.subplots(num_rows, num_cols, figsize=(30, 10 * num_rows))\n            axes = axes.flatten()  # Flatten the 2D array into 1D\n\n            # Plot each metric\n            for i in range(num_plots):\n                \n                ax = axes[i]\n                ax.plot(data[i]['val'], c=colors[0], label=\"val\")\n                ax.plot(data[i]['train'], c=colors[-1], label=\"train\")\n                ax.set_title(labels[i])\n                ax.legend(loc=\"upper right\")\n\n            # Hide unused subplots\n            for i in range(num_plots, num_rows * num_cols):\n               \n                axes[i].axis('off')\n\n            plt.tight_layout()\n            plt.show()\n\n        \"\"\"\"with plt.style.context(\"seaborn-dark-palette\"):\n            fig, axes = plt.subplots(6, 3, figsize=(30, 30))\n            axes = axes.flatten() \n            for i, ax in enumerate(axes):\n                ax.plot(data[i]['val'], c=colors[0], label=\"val\")\n                ax.plot(data[i]['train'], c=colors[-1], label=\"train\")\n                ax.set_title(labels[i])\n                ax.legend(loc=\"upper right\")\n                \n            plt.tight_layout()\n            plt.show()\"\"\"\n\n    def _save_train_history(self):\n        print(\"Saving final model and logs...\")\n        torch.save(self.net.state_dict(), \"final_model.pth\")\n\n        logs_ = [self.losses, self.dice_scores, self.jaccard_scores, self.acc_scores, self.sen_scores, self.spf_scores]\n        log_names_ = [\"_loss\", \"_dice\", \"_jaccard\",\"_acc\", \"_sen\", \"_spf\"]\n        logs = [logs_[i][key] for i in range(len(logs_)) for key in logs_[i]]\n        log_names = [key + log_names_[i] for i in range(len(logs_)) for key in logs_[i]]\n\n        pd.DataFrame(dict(zip(log_names, logs))).to_csv(\"train_log.csv\", index=False)","metadata":{"_uuid":"f0122dd1-c41a-4129-bf06-dcba202c7141","_cell_guid":"2f4684b0-168d-4909-8bde-c82979973aae","trusted":true,"collapsed":false,"papermill":{"duration":0.039576,"end_time":"2022-09-19T19:05:08.340371","exception":false,"start_time":"2022-09-19T19:05:08.300795","status":"completed"},"tags":[],"id":"b9188127","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-03T08:13:02.907832Z","iopub.execute_input":"2025-05-03T08:13:02.908099Z","iopub.status.idle":"2025-05-03T08:13:02.929333Z","shell.execute_reply.started":"2025-05-03T08:13:02.908069Z","shell.execute_reply":"2025-05-03T08:13:02.928595Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"nodel=ViT_CNN_Segmentation()\nprint(nodel)\nsum([param.nelement() for param in nodel.parameters()])","metadata":{"_uuid":"ff442971-67f9-42b8-8f82-93748c09eaad","_cell_guid":"c2ee7a23-61d4-47e8-908c-bda7ba0c0b56","trusted":true,"collapsed":false,"papermill":{"duration":0.045985,"end_time":"2022-09-19T19:05:08.394633","exception":false,"start_time":"2022-09-19T19:05:08.348648","status":"completed"},"tags":[],"id":"4d23804b","outputId":"27ced682-e768-4935-efd9-7af11851987c","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    net=nodel,\n    dataset=BratsDataset,\n    criterion=BCEDiceLoss(),\n    lr=1e-4,\n    accumulation_steps=4,\n    batch_size=1,\n    fold=0,\n    num_epochs=100,\n    path_to_csv=config.path_to_csv\n)","metadata":{"_uuid":"881a1deb-0208-4fca-a720-44d4e43addc5","_cell_guid":"534cfafa-572a-4a52-8859-d53c84d54881","trusted":true,"collapsed":false,"papermill":{"duration":0.217232,"end_time":"2022-09-19T19:05:08.622764","exception":false,"start_time":"2022-09-19T19:05:08.405532","status":"completed"},"tags":[],"id":"1fe284fe","outputId":"3f9e9529-660e-42cc-df8d-8858ac148dd7","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\ntrainer.run()","metadata":{"_uuid":"d0188fd7-a41a-412f-a25a-1cb0ca9c5d2c","_cell_guid":"8130c523-39d5-4ea2-9196-a9235aded782","trusted":true,"collapsed":false,"papermill":{"duration":187.046654,"end_time":"2022-09-19T19:08:15.687873","exception":false,"start_time":"2022-09-19T19:05:08.641219","status":"completed"},"tags":[],"id":"3ba8d04f","outputId":"8777dfe7-b3ed-4e8c-e9c6-0b7ab7d63cfb","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_scores_per_classes(model,\n                               dataloader,\n                               classes):\n    # coeficientii dice pentru fiecare clasă\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    dice_scores_per_classes = {key: list() for key in classes}\n    iou_scores_per_classes = {key: list() for key in classes}\n    sen_scores_per_classes = {key: list() for key in classes}\n    spf_scores_per_classes = {key: list() for key in classes}\n\n\n    with torch.no_grad(): # pentru setul de validare nu vrem sa mai învețe modelul\n        for i, data in enumerate(dataloader):\n            imgs, targets = data['image'], data['mask']\n            imgs, targets = imgs.to(device), targets.to(device)\n            logits = model(imgs)\n            logits = logits.detach().cpu().numpy()\n            targets = targets.detach().cpu().numpy()\n\n            dice_scores = dice_coef_metric_per_classes(logits, targets)\n            iou_scores = jaccard_coef_metric_per_classes(logits, targets)\n            sen_scores = sen_coef_metric_per_classes(logits, targets)\n            spf_scores = spf_coef_metric_per_classes(logits, targets)\n\n            for key in dice_scores.keys():\n                dice_scores_per_classes[key].extend(dice_scores[key])\n\n            for key in iou_scores.keys():\n                iou_scores_per_classes[key].extend(iou_scores[key])\n\n            for key in sen_scores.keys():\n                sen_scores_per_classes[key].extend(sen_scores[key])\n\n            for key in spf_scores.keys():\n                spf_scores_per_classes[key].extend(spf_scores[key])\n\n    return dice_scores_per_classes, iou_scores_per_classes, sen_scores_per_classes, spf_scores_per_classes","metadata":{"_uuid":"4d1fefc0-08f6-4801-a1b2-546f9da80a16","_cell_guid":"0586efd0-88a9-44d1-b309-b22323d96f8a","trusted":true,"collapsed":false,"papermill":{"duration":0.023381,"end_time":"2022-09-19T19:08:15.721973","exception":false,"start_time":"2022-09-19T19:08:15.698592","status":"completed"},"tags":[],"id":"e57bfa7c","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_dataloader = get_dataloader(BratsDataset, 'train_data.csv', phase='valid', fold=0)\nlen(val_dataloader)\n","metadata":{"_uuid":"6dbd6829-7a2e-49c2-b0c2-1be0e50383c3","_cell_guid":"7fe4f4b5-0b7f-4aa9-8b5b-c383315775e3","trusted":true,"collapsed":false,"papermill":{"duration":0.026159,"end_time":"2022-09-19T19:08:15.757526","exception":false,"start_time":"2022-09-19T19:08:15.731367","status":"completed"},"tags":[],"id":"feb21315","outputId":"b00d161e-b668-426e-d634-78cded4dc76a","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nodel.eval();","metadata":{"_uuid":"72bd30f2-80a3-48e6-9c19-eef9d112f42a","_cell_guid":"734de247-5fa8-4092-a678-815220ef5034","trusted":true,"collapsed":false,"papermill":{"duration":0.017702,"end_time":"2022-09-19T19:08:15.784620","exception":false,"start_time":"2022-09-19T19:08:15.766918","status":"completed"},"tags":[],"id":"0351ae36","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\ndice_scores_per_classes, iou_scores_per_classes, sen_scores_per_classes, spf_scores_per_classes = compute_scores_per_classes(nodel, val_dataloader, ['WT', 'TC', 'ET'])","metadata":{"_uuid":"497fb7bd-7ddb-4ab5-a414-b66bec006848","_cell_guid":"16d02d2c-e575-40ea-919c-7d4ec00d51cd","trusted":true,"collapsed":false,"papermill":{"duration":12.221094,"end_time":"2022-09-19T19:08:28.015197","exception":false,"start_time":"2022-09-19T19:08:15.794103","status":"completed"},"tags":[],"id":"8792fb5d","outputId":"53d9aa91-deb1-490e-e93f-dcecf80e1b13","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dice_df = pd.DataFrame(dice_scores_per_classes)\n# dice_df.columns = ['WT dice', 'TC dice', 'ET dice']\n# print(dice_df.head(5))\n# val_metics_df = dice_df.loc[:, ['WT dice', 'TC dice', 'ET dice']]\n# print(val_metics_df)\ndice_df = pd.DataFrame(dice_scores_per_classes)\ndice_df.columns = ['WT dice', 'TC dice', 'ET dice']\n\niou_df = pd.DataFrame(iou_scores_per_classes)\niou_df.columns = ['WT iou', 'TC iou', 'ET iou']\n\nsen_df = pd.DataFrame(sen_scores_per_classes)\nsen_df.columns = ['WT sen', 'TC sen', 'ET sen']\n\nspf_df = pd.DataFrame(spf_scores_per_classes)\nspf_df.columns = ['WT spf', 'TC spf', 'ET spf']\n\nval_metics_df = pd.concat([dice_df, iou_df, sen_df, spf_df], axis=1, sort=True)\nval_metics_df = val_metics_df.loc[:, ['WT dice', 'WT iou', 'WT sen','WT spf',\n                                      'TC dice', 'TC iou', 'TC sen', 'TC spf',\n                                      'ET dice', 'ET iou', 'ET sen', 'ET spf']]\nval_metics_df.sample(5)","metadata":{"_uuid":"8d0ab288-35ba-4970-929c-75ede3257d6d","_cell_guid":"6d6738a1-bd95-4409-8d77-b4dff2496d44","trusted":true,"collapsed":false,"papermill":{"duration":0.042669,"end_time":"2022-09-19T19:08:28.068470","exception":false,"start_time":"2022-09-19T19:08:28.025801","status":"completed"},"tags":[],"id":"37683661","outputId":"c9b5993e-bec9-4011-ab84-04e5772bb769","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"colors = ['royalblue', 'royalblue','royalblue', 'royalblue', 'lightcoral', 'lightcoral','lightcoral','lightcoral', 'greenyellow', 'greenyellow', 'greenyellow', 'greenyellow']\npalette = sns.color_palette(colors, 12)\n\nfig, ax = plt.subplots(figsize=(20, 20));\nsns.barplot(x=val_metics_df.mean().index, y=val_metics_df.mean(), palette=palette, ax=ax);\nax.set_xticklabels(val_metics_df.columns, fontsize=16);\nax.set_title(\"Coefficient scores\", fontsize=20)\n\nfor idx, p in enumerate(ax.patches):\n        percentage = '{:.1f}%'.format(100 * val_metics_df.mean().values[idx])\n        x = p.get_x() + p.get_width() / 2 - 0.15\n        y = p.get_y() + p.get_height()\n        ax.annotate(percentage, (x, y), fontsize=16)","metadata":{"_uuid":"a8668386-fd67-481f-b6d9-ae64b531ff71","_cell_guid":"38cf9305-2c23-4e9c-85fe-3332232717e1","trusted":true,"collapsed":false,"papermill":{"duration":0.367883,"end_time":"2022-09-19T19:08:28.446128","exception":false,"start_time":"2022-09-19T19:08:28.078245","status":"completed"},"tags":[],"id":"f955cb15","outputId":"56063b6f-6f39-4fa5-f394-1fafdcb5cfee","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_results(model,\n                    dataloader,\n                    treshold=0.33):\n\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    results = {\"Id\": [],\"image\": [], \"GT\": [],\"Prediction\": []}\n\n    with torch.no_grad():\n        for i, data in enumerate(dataloader):\n            id_, imgs, targets = data['Id'], data['image'], data['mask']\n            imgs, targets = imgs.to(device), targets.to(device)\n            logits = model(imgs)\n            probs = torch.sigmoid(logits)\n\n            predictions = (probs >= treshold).float()\n            predictions =  predictions.cpu()\n            targets = targets.cpu()\n\n            results[\"Id\"].append(id_)\n            results[\"image\"].append(imgs.cpu())\n            results[\"GT\"].append(targets)\n            results[\"Prediction\"].append(predictions)\n\n            # only 5 pars\n            if (i > 10):\n                return results\n            print(results['Id'])\n        return results","metadata":{"_uuid":"6fce96c3-c2ac-4e15-8e0d-8b27f71066a0","_cell_guid":"b576f2ff-3e18-466b-8128-96c25954b459","trusted":true,"collapsed":false,"papermill":{"duration":0.022686,"end_time":"2022-09-19T19:08:28.479474","exception":false,"start_time":"2022-09-19T19:08:28.456788","status":"completed"},"tags":[],"id":"7a0bc400","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nresults = compute_results(nodel, val_dataloader, 0.33)","metadata":{"_uuid":"524b2101-1697-4243-9da1-7b563292990b","_cell_guid":"be0eca1c-bd88-4cf0-9fb3-8ddb45d92a51","trusted":true,"collapsed":false,"papermill":{"duration":5.081006,"end_time":"2022-09-19T19:08:33.570966","exception":false,"start_time":"2022-09-19T19:08:28.489960","status":"completed"},"tags":[],"id":"37890a71","outputId":"68497ce2-6155-49cf-8b93-028ee93090e3","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for id_, img, gt, prediction in zip(results['Id'],\n                    results['image'],\n                    results['GT'],\n                    results['Prediction']\n                    ):\n\n    print(id_)","metadata":{"_uuid":"dba46db6-fc24-47ba-ab52-27682ec09beb","_cell_guid":"1a5ffb2a-cfc1-42fa-88fe-6d56ac7f36a0","trusted":true,"collapsed":false,"papermill":{"duration":0.02313,"end_time":"2022-09-19T19:08:33.606698","exception":false,"start_time":"2022-09-19T19:08:33.583568","status":"completed"},"tags":[],"id":"097df561","outputId":"7f1bd9e9-98d0-47f0-c0e0-2e3c593b07db","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from skimage.util import montage\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass ShowResult:\n    def mask_preprocessing(self, mask):\n        \"\"\"\n        Processes segmentation masks for visualization.\n        \"\"\"\n        mask = mask.squeeze().cpu().detach().numpy()\n        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))  # Ensure correct ordering\n\n        mask_WT = np.rot90(montage(mask[0]))  # Whole Tumor\n        mask_TC = np.rot90(montage(mask[1]))  # Tumor Core\n        mask_ET = np.rot90(montage(mask[2]))  # Enhancing Tumor\n\n        return mask_WT, mask_TC, mask_ET\n\n    def image_preprocessing(self, image):\n        \"\"\"\n        Extracts FLAIR and T2 images for visualization.\n        \"\"\"\n        image = image.squeeze().cpu().detach().numpy()\n        image = np.moveaxis(image, (0, 1, 2, 3), (0, 3, 2, 1))  # (C, D, H, W) -> (C, H, W, D)\n\n        flair_img = np.rot90(montage(image[0]))  # Assuming Channel 0 is FLAIR\n        t2_img = np.rot90(montage(image[1]))  # Assuming Channel 1 is T2\n\n        return flair_img, t2_img\n\n    def plot(self, image, ground_truth, prediction):\n        \"\"\"\n        Plots FLAIR, T2, ground truth, and prediction segmentations with larger plots (2 per row).\n        \"\"\"\n        flair_img, t2_img = self.image_preprocessing(image)\n        gt_mask_WT, gt_mask_TC, gt_mask_ET = self.mask_preprocessing(ground_truth)\n        pr_mask_WT, pr_mask_TC, pr_mask_ET = self.mask_preprocessing(prediction)\n\n        fig, axes = plt.subplots(3, 2, figsize=(20, 30))  # 3 rows, 2 columns (larger images)\n        [ax.axis(\"off\") for ax in axes.ravel()]  \n\n        # FLAIR Image\n        axes[0, 0].set_title(\"FLAIR Image\", fontsize=20, weight='bold')\n        axes[0, 0].imshow(flair_img, cmap='bone')\n\n        # T2 Image\n        axes[0, 1].set_title(\"T2 Image\", fontsize=20, weight='bold')\n        axes[0, 1].imshow(t2_img, cmap='bone')\n\n        # Ground Truth Segmentation\n        axes[1, 0].set_title(\"Ground Truth\", fontsize=20, weight='bold')\n        axes[1, 0].imshow(flair_img, cmap='bone')  # Overlay GT on FLAIR\n        axes[1, 0].imshow(np.ma.masked_where(gt_mask_WT == 0, gt_mask_WT), cmap='cool_r', alpha=0.6)\n        axes[1, 0].imshow(np.ma.masked_where(gt_mask_TC == 0, gt_mask_TC), cmap='YlGnBu', alpha=0.6)\n        axes[1, 0].imshow(np.ma.masked_where(gt_mask_ET == 0, gt_mask_ET), cmap='cool', alpha=0.6)\n\n        # Prediction Segmentation\n        axes[1, 1].set_title(\"Prediction\", fontsize=20, weight='bold')\n        axes[1, 1].imshow(flair_img, cmap='bone')  # Overlay Prediction on FLAIR\n        axes[1, 1].imshow(np.ma.masked_where(pr_mask_WT == 0, pr_mask_WT), cmap='cool_r', alpha=0.6)\n        axes[1, 1].imshow(np.ma.masked_where(pr_mask_TC == 0, pr_mask_TC), cmap='autumn_r', alpha=0.6)\n        axes[1, 1].imshow(np.ma.masked_where(pr_mask_ET == 0, pr_mask_ET), cmap='autumn', alpha=0.6)\n\n        plt.tight_layout()\n        plt.show()\nshow_result = ShowResult()\nfor id_, img, gt, prediction in zip(results['Id'], results['image'], results['GT'], results['Prediction']):\n    print(f\"Displaying results for ID: {id_}\")\n    show_result.plot(img, gt, prediction)","metadata":{"_uuid":"30cdd0a0-3577-44d0-9e89-b9f5540dd15c","_cell_guid":"e33a2102-18ef-4b68-a521-58a405514e90","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#SINGLE SLICE 64TH\nfrom skimage.util import montage\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass ShowResult:\n    def __init__(self, slice_idx=64):\n        \"\"\"\n        Initialize with the desired slice index (default is 64).\n        \"\"\"\n        self.slice_idx = slice_idx\n\n    def mask_preprocessing(self, mask):\n        \"\"\"\n        Processes segmentation masks for visualization, extracting the specified slice.\n        \"\"\"\n        mask = mask.squeeze().cpu().detach().numpy()\n        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))  # Ensure correct ordering\n\n        # Extract the specified slice\n        mask_WT = mask[0, :, :, self.slice_idx]  # Whole Tumor\n        mask_TC = mask[1, :, :, self.slice_idx]  # Tumor Core\n        mask_ET = mask[2, :, :, self.slice_idx]  # Enhancing Tumor\n\n        return mask_WT, mask_TC, mask_ET\n\n    def image_preprocessing(self, image):\n        \"\"\"\n        Extracts FLAIR and T2 images for visualization, extracting the specified slice.\n        \"\"\"\n        image = image.squeeze().cpu().detach().numpy()\n        image = np.moveaxis(image, (0, 1, 2, 3), (0, 3, 2, 1))  # (C, D, H, W) -> (C, H, W, D)\n\n        # Extract the specified slice\n        flair_img = image[0, :, :, self.slice_idx]  # Assuming Channel 0 is FLAIR\n        t2_img = image[1, :, :, self.slice_idx]  # Assuming Channel 1 is T2\n\n        return flair_img, t2_img\n\n    def plot(self, image, ground_truth, prediction):\n        \"\"\"\n        Plots FLAIR, T2, ground truth, and prediction segmentations for the specified slice.\n        \"\"\"\n        flair_img, t2_img = self.image_preprocessing(image)\n        gt_mask_WT, gt_mask_TC, gt_mask_ET = self.mask_preprocessing(ground_truth)\n        pr_mask_WT, pr_mask_TC, pr_mask_ET = self.mask_preprocessing(prediction)\n        black_bg = np.zeros((240, 240))\n        fig, axes = plt.subplots(1, 4, figsize=(10, 15))  # 3 rows, 2 columns (larger images)\n        [ax.axis(\"off\") for ax in axes.ravel()]  \n\n        # FLAIR Image\n        axes[0].set_title(\"FLAIR Image\", fontsize=14, weight='bold')\n        axes[0].imshow(flair_img, cmap='bone')\n\n        # T2 Image\n        axes[1].set_title(\"T2 Image\", fontsize=14, weight='bold')\n        axes[1].imshow(t2_img, cmap='bone')\n\n        # Ground Truth Segmentation\n        axes[2].set_title(\"Ground Truth\", fontsize=14, weight='bold')\n        axes[2].imshow(flair_img, cmap='bone')  # Overlay GT on FLAIR\n        #axes[2].imshow(black_bg, cmap='gray', vmin=0, vmax=1)\n        axes[2].imshow(np.ma.masked_where(gt_mask_WT == 0, gt_mask_WT), cmap='cool_r', alpha=1.0)\n        axes[2].imshow(np.ma.masked_where(gt_mask_TC == 0, gt_mask_TC), cmap='autumn_r', alpha=1.0)\n        axes[2].imshow(np.ma.masked_where(gt_mask_ET == 0, gt_mask_ET), cmap='autumn', alpha=1.0)\n\n        # Prediction Segmentation\n        axes[3].set_title(\"Prediction\", fontsize=14, weight='bold')\n        axes[3].imshow(flair_img, cmap='bone')  # Overlay Prediction on FLAIR\n        axes[3].imshow(np.ma.masked_where(pr_mask_WT == 0, pr_mask_WT), cmap='cool_r', alpha=1.0)\n        axes[3].imshow(np.ma.masked_where(pr_mask_TC == 0, pr_mask_TC), cmap='autumn_r', alpha=1.0)\n        axes[3].imshow(np.ma.masked_where(pr_mask_ET == 0, pr_mask_ET), cmap='autumn', alpha=1.0)\n\n        plt.tight_layout()\n        plt.show()\n\n# Initialize with the desired slice index (e.g., 64)\nshow_result = ShowResult(slice_idx=64)\n\n# Iterate through results and plot\nfor id_, img, gt, prediction in zip(results['Id'], results['image'], results['GT'], results['Prediction']):\n    print(f\"Displaying results for ID: {id_}\")\n    show_result.plot(img, gt, prediction)","metadata":{"_uuid":"9c06d551-f6ee-42e0-9956-903f8bb0b642","_cell_guid":"ca5866ea-b126-429e-ad61-620ad0c1319f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**EXTERNAL VALIDATION **","metadata":{"_uuid":"a42052a2-7f96-40de-9ce7-b1b11ba1a816","_cell_guid":"2418e181-40a9-4d75-805c-f449af64e706","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport nibabel as nib\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.nn import MSELoss\nfrom sklearn.metrics import accuracy_score\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","metadata":{"_uuid":"4e2e0a16-e0e8-415e-8037-eb559348101c","_cell_guid":"ac488392-020a-477e-b9fb-f4513ccf3cfd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model =  AttentionUNet3D(in_channels=4, out_channels=3, init_channels=32)\nmodel.load_state_dict(torch.load('/kaggle/input/attenunet/pytorch/default/1/attenunet_best_model (1).pth'))\nmodel.eval()","metadata":{"_uuid":"1c557805-3b5e-4cbd-8280-ae1ba76f4447","_cell_guid":"c54dd5aa-024c-4b91-972c-e8db77f5e559","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the dataset class for BraTS 2018\nclass Brats2018Dataset(Dataset):\n    def __init__(self, df, phase='test'):\n        self.df = df\n        self.phase = phase\n        self.data_types = ['_flair.nii', '_t1.nii', '_t1ce.nii', '_t2.nii']\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        id_ = self.df.loc[idx, 'BraTS18ID']\n        root_path = self.df.loc[self.df['BraTS18ID'] == id_]['path'].values[0]\n        images = []\n        for data_type in self.data_types:\n            img_path = os.path.join(root_path, id_ + data_type)\n            img = self.load_img(img_path)\n            img = self.center_crop(img, 128, 128, 128)\n            img = self.normalize(img)\n            images.append(img)\n        img = np.stack(images)\n        img = np.moveaxis(img, (0, 1, 2, 3), (0, 3, 2, 1))\n\n        if self.phase == 'test':\n            mask_path = os.path.join(root_path, id_ + \"_seg.nii\")\n            mask = self.load_img(mask_path)\n            mask = self.center_crop(mask, 128, 128, 128)\n            mask = self.preprocess_mask_labels(mask)\n            return {\n                \"Id\": id_,\n                \"image\": img,\n                \"mask\": mask,\n            }\n        #return {\n            #\"Id\": id_,\n            #\"image\": img,\n        #}\n\n    def load_img(self, file_path):\n        data = nib.load(file_path)\n        return np.asarray(data.dataobj)\n\n    def normalize(self, data):\n        data_min = np.min(data)\n        return (data - data_min) / (np.max(data) - data_min)\n\n    def center_crop(self, data, crop_height, crop_width, crop_depth):\n        height, width, depth = data.shape[:3]\n        x1 = (height - crop_height) // 2\n        x2 = x1 + crop_height\n        y1 = (width - crop_width) // 2\n        y2 = y1 + crop_width\n        z1 = (depth - crop_depth) // 2\n        z2 = z1 + crop_depth\n        return data[x1:x2, y1:y2, z1:z2]\n\n    def preprocess_mask_labels(self, mask):\n        mask_WT = mask.copy()\n        mask_WT[mask_WT == 1] = 1\n        mask_WT[mask_WT == 2] = 1\n        mask_WT[mask_WT == 4] = 1\n\n        mask_TC = mask.copy()\n        mask_TC[mask_TC == 1] = 1\n        mask_TC[mask_TC == 2] = 0\n        mask_TC[mask_TC == 4] = 1\n\n        mask_ET = mask.copy()\n        mask_ET[mask_ET == 1] = 0\n        mask_ET[mask_ET == 2] = 0\n        mask_ET[mask_ET == 4] = 1\n\n        mask = np.stack([mask_WT, mask_TC, mask_ET])\n        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))\n        return mask","metadata":{"_uuid":"c985b71b-d4a9-47af-afde-f947ec3657ae","_cell_guid":"8c211539-3d05-46c2-bf1a-43ccc47c0eb6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the BraTS 2018 dataset\nbrats2018_df = pd.read_csv('/kaggle/input/archive/archive/MICCAI_BraTS_2018_Data_Training/survival_data.csv')\nbrats2018_df['path'] = brats2018_df['BraTS18ID'].apply(lambda x: os.path.join(\"/kaggle/input/archive/archive/MICCAI_BraTS_2018_Data_Training/\", x))\n# Create the dataset and dataloader\nbrats2018_dataset = Brats2018Dataset(brats2018_df, phase='test')\nbrats2018_dataloader = DataLoader(brats2018_dataset, batch_size=1, num_workers=4, pin_memory=True, shuffle=False)","metadata":{"_uuid":"83440abd-2da0-4b14-b775-f3d259df29ab","_cell_guid":"2dc1b048-902d-45a1-a24d-ac7f38511397","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"brats2018_df","metadata":{"_uuid":"32b0fff7-a4e3-422c-95f9-8c8eb41a86fa","_cell_guid":"4e3b673f-bbfb-4498-b74c-3ee3ef37fae2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the evaluation metrics\ndef dice_coef_metric(probabilities, truth, threshold=0.5, eps=1e-9):\n    scores = []\n    num = probabilities.shape[0]\n    predictions = (probabilities >= threshold).float()\n    assert(predictions.shape == truth.shape)\n    for i in range(num):\n        prediction = predictions[i]\n        truth_ = truth[i]\n        intersection = 2.0 * (truth_ * prediction).sum()\n        union = truth_.sum() + prediction.sum()\n        if truth_.sum() == 0 and prediction.sum() == 0:\n            scores.append(1.0)\n        else:\n            scores.append((intersection + eps) / union)\n    return np.mean(scores)\n\ndef jaccard_coef_metric(probabilities, truth, threshold=0.5, eps=1e-9):\n    scores = []\n    num = probabilities.shape[0]\n    predictions = (probabilities >= threshold).float()\n    assert(predictions.shape == truth.shape)\n    for i in range(num):\n        prediction = predictions[i]\n        truth_ = truth[i]\n        intersection = (prediction * truth_).sum()\n        union = (prediction.sum() + truth_.sum()) - intersection + eps\n        if truth_.sum() == 0 and prediction.sum() == 0:\n            scores.append(1.0)\n        else:\n            scores.append((intersection + eps) / union)\n    return np.mean(scores)\n\ndef accuracy_coef_metric(probabilities, truth, threshold=0.5, eps=1e-9):\n    scores = []\n    num = probabilities.shape[0]\n    predictions = (probabilities >= threshold).float()\n    assert predictions.shape == truth.shape\n    for i in range(num):\n        prediction = predictions[i]\n        truth_ = truth[i]\n        correct = (prediction == truth_).sum().item()\n        total = truth_.numel()\n        scores.append(correct / total)\n    return np.mean(scores)\n\n# Compute loss: BCE Loss + Dice Loss\ndef compute_loss(probabilities, truth, eps=1e-9):\n    bce_loss = F.binary_cross_entropy(probabilities, truth)\n    \n    # Compute dice loss\n    dice_score = dice_coef_metric(probabilities, truth)\n    dice_loss = 1 - dice_score  # Dice loss is 1 - Dice coefficient\n\n    return bce_loss + dice_loss","metadata":{"_uuid":"01ce75b6-0435-4b9a-99d7-44cb9c5053d7","_cell_guid":"6d6b882c-6a18-4652-a23a-80988e20b9ee","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)  # Ensure model is on the same device\n\n# Evaluate the model on the BraTS 2018 dataset\nloss_scores = []\ndice_scores = []\niou_scores = []\nacc_scores = []\n\nwith torch.no_grad():\n    for data in tqdm(brats2018_dataloader):\n        images = data['image'].to(device).float()\n        masks = data['mask'].to(device).float()\n        logits = model(images)\n        probs = torch.sigmoid(logits)\n\n        # Move tensors to CPU before converting to NumPy\n        probs_cpu = probs.cpu()\n        masks_cpu = masks.cpu()\n\n        # Calculate metrics\n        dice = dice_coef_metric(probs_cpu, masks_cpu)\n        iou = jaccard_coef_metric(probs_cpu, masks_cpu)\n        acc = accuracy_coef_metric(probs_cpu, masks_cpu)\n        loss = compute_loss(probs_cpu, masks_cpu)  # Compute loss\n\n        # Append scores to lists\n        loss_scores.append(loss)\n        dice_scores.append(dice)\n        iou_scores.append(iou)\n        acc_scores.append(acc)\n\n# Calculate mean scores\nprint(f\"Loss Score(BCE + DICE LOSS): {np.mean(loss_scores)}\")\nprint(f\"Dice Score: {np.mean(dice_scores)}\")\nprint(f\"IoU Score: {np.mean(iou_scores)}\")\nprint(f\"Accuracy Score: {np.mean(acc_scores)}\")","metadata":{"_uuid":"8c98a014-4793-427f-a181-5cc13f5ba511","_cell_guid":"458675de-518b-40fe-8342-bb0c93a33291","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_results(model,\n                    dataloader,\n                    treshold=0.33):\n\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    results = {\"Id\": [],\"image\": [], \"GT\": [],\"Prediction\": []}\n\n    with torch.no_grad():\n        for i, data in enumerate(dataloader):\n            id_, imgs, targets = data['Id'], data['image'], data['mask']\n            imgs, targets = imgs.to(device), targets.to(device)\n\n            # Convert to float32 before moving to device\n            imgs, targets = imgs.float().to(device), targets.float().to(device)\n            \n            logits = model(imgs)\n            probs = torch.sigmoid(logits)\n            \n            predictions = (probs >= treshold).float()\n            predictions =  predictions.cpu()\n            targets = targets.cpu()\n            \n            results[\"Id\"].append(id_)\n            results[\"image\"].append(imgs.cpu())\n            results[\"GT\"].append(targets)\n            results[\"Prediction\"].append(predictions)\n            \n            # only 5 pars\n            if (i > 60):    \n                return results\n        return results","metadata":{"_uuid":"7ae20c52-5008-486d-bf0c-b76fc40a0284","_cell_guid":"53c298f6-5288-4d25-b9b8-c5bdb006208e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nexternal_results = compute_results(model, brats2018_dataloader, 0.33)\n\nfor id_, img, gt, prediction in zip(external_results['Id'],\n                    external_results['image'],\n                    external_results['GT'],\n                    external_results['Prediction']\n                    ):\n\n    print(id_)","metadata":{"_uuid":"9ef05854-db72-44a6-ad3a-a18b0428b792","_cell_guid":"11a2a9a3-2b6d-40a2-8026-379154450422","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from skimage.util import montage\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass ShowResult:\n    def mask_preprocessing(self, mask):\n        \"\"\"\n        Processes segmentation masks for visualization.\n        \"\"\"\n        mask = mask.squeeze().cpu().detach().numpy()\n        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))  # Ensure correct ordering\n\n        mask_WT = np.rot90(montage(mask[0]))  # Whole Tumor\n        mask_TC = np.rot90(montage(mask[1]))  # Tumor Core\n        mask_ET = np.rot90(montage(mask[2]))  # Enhancing Tumor\n\n        return mask_WT, mask_TC, mask_ET\n\n    def image_preprocessing(self, image):\n        \"\"\"\n        Extracts FLAIR and T2 images for visualization.\n        \"\"\"\n        image = image.squeeze().cpu().detach().numpy()\n        image = np.moveaxis(image, (0, 1, 2, 3), (0, 3, 2, 1))  # (C, D, H, W) -> (C, H, W, D)\n\n        flair_img = np.rot90(montage(image[0]))  # Assuming Channel 0 is FLAIR\n        t2_img = np.rot90(montage(image[1]))  # Assuming Channel 1 is T2\n\n        return flair_img, t2_img\n\n    def plot(self, image, ground_truth, prediction):\n        \"\"\"\n        Plots FLAIR, T2, ground truth, and prediction segmentations with larger plots (2 per row).\n        \"\"\"\n        flair_img, t2_img = self.image_preprocessing(image)\n        gt_mask_WT, gt_mask_TC, gt_mask_ET = self.mask_preprocessing(ground_truth)\n        pr_mask_WT, pr_mask_TC, pr_mask_ET = self.mask_preprocessing(prediction)\n\n        fig, axes = plt.subplots(3, 2, figsize=(20, 30))  \n        [ax.axis(\"off\") for ax in axes.ravel()]  \n\n        # FLAIR Image\n        axes[0, 0].set_title(\"FLAIR Image\", fontsize=20, weight='bold')\n        axes[0, 0].imshow(flair_img, cmap='bone')\n\n        # T2 Image\n        axes[0, 1].set_title(\"T2 Image\", fontsize=20, weight='bold')\n        axes[0, 1].imshow(t2_img, cmap='bone')\n\n        # Ground Truth Segmentation\n        axes[1, 0].set_title(\"Ground Truth\", fontsize=20, weight='bold')\n        axes[1, 0].imshow(flair_img, cmap='bone')  # Overlay GT on FLAIR\n        axes[1, 0].imshow(np.ma.masked_where(gt_mask_WT == 0, gt_mask_WT), cmap='cool_r', alpha=0.6)\n        axes[1, 0].imshow(np.ma.masked_where(gt_mask_TC == 0, gt_mask_TC), cmap='YlGnBu', alpha=0.6)\n        axes[1, 0].imshow(np.ma.masked_where(gt_mask_ET == 0, gt_mask_ET), cmap='cool', alpha=0.6)\n\n        # Prediction Segmentation\n        axes[1, 1].set_title(\"Prediction\", fontsize=20, weight='bold')\n        axes[1, 1].imshow(flair_img, cmap='bone')  # Overlay Prediction on FLAIR\n        axes[1, 1].imshow(np.ma.masked_where(pr_mask_WT == 0, pr_mask_WT), cmap='cool_r', alpha=0.6)\n        axes[1, 1].imshow(np.ma.masked_where(pr_mask_TC == 0, pr_mask_TC), cmap='autumn_r', alpha=0.6)\n        axes[1, 1].imshow(np.ma.masked_where(pr_mask_ET == 0, pr_mask_ET), cmap='autumn', alpha=0.6)\n\n        plt.tight_layout()\n        plt.show()\n\nshow_result = ShowResult()\nfor id_, img, gt, prediction in zip(external_results['Id'], external_results['image'], external_results['GT'], external_results['Prediction']):\n    print(f\"Displaying results for ID: {id_}\")\n    show_result.plot(img, gt, prediction)","metadata":{"_uuid":"0c3cc1ad-1edb-4cb1-b9dc-da87d70874df","_cell_guid":"11f9d559-10fb-4efb-8585-ada437ef7bdc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from skimage.util import montage\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass ShowResult:\n    def __init__(self, slice_idx=64):\n        \"\"\"\n        Initialize with the desired slice index (default is 64).\n        \"\"\"\n        self.slice_idx = slice_idx\n\n    def mask_preprocessing(self, mask):\n        \"\"\"\n        Processes segmentation masks for visualization, extracting the specified slice.\n        \"\"\"\n        mask = mask.squeeze().cpu().detach().numpy()\n        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))  # Ensure correct ordering\n\n        # Extract the specified slice\n        mask_WT = mask[0, :, :, self.slice_idx]  # Whole Tumor\n        mask_TC = mask[1, :, :, self.slice_idx]  # Tumor Core\n        mask_ET = mask[2, :, :, self.slice_idx]  # Enhancing Tumor\n\n        return mask_WT, mask_TC, mask_ET\n\n    def image_preprocessing(self, image):\n        \"\"\"\n        Extracts FLAIR and T2 images for visualization, extracting the specified slice.\n        \"\"\"\n        image = image.squeeze().cpu().detach().numpy()\n        image = np.moveaxis(image, (0, 1, 2, 3), (0, 3, 2, 1))  # (C, D, H, W) -> (C, H, W, D)\n\n        # Extract the specified slice\n        flair_img = image[0, :, :, self.slice_idx]  # Assuming Channel 0 is FLAIR\n        t2_img = image[1, :, :, self.slice_idx]  # Assuming Channel 1 is T2\n\n        return flair_img, t2_img\n\n    def plot(self, image, ground_truth, prediction):\n        \"\"\"\n        Plots FLAIR, T2, ground truth, and prediction segmentations for the specified slice.\n        \"\"\"\n        flair_img, t2_img = self.image_preprocessing(image)\n        gt_mask_WT, gt_mask_TC, gt_mask_ET = self.mask_preprocessing(ground_truth)\n        pr_mask_WT, pr_mask_TC, pr_mask_ET = self.mask_preprocessing(prediction)\n        black_bg = np.zeros((240, 240))\n        print(\"FLAIR image shape:\", flair_img.shape)\n        print(\"GT mask shape:\", gt_mask_WT.shape)\n\n        fig, axes = plt.subplots(1, 4, figsize=(10, 15))  # 3 rows, 2 columns (larger images)\n        [ax.axis(\"off\") for ax in axes.ravel()]  \n\n        # FLAIR Image\n        axes[0].set_title(\"FLAIR Image\", fontsize=14, weight='bold')\n        axes[0].imshow(flair_img, cmap='bone')\n\n        # T2 Image\n        axes[1].set_title(\"T2 Image\", fontsize=14, weight='bold')\n        axes[1].imshow(t2_img, cmap='bone')\n\n        # Ground Truth Segmentation\n        axes[2].set_title(\"Ground Truth\", fontsize=14, weight='bold')\n        axes[2].imshow(flair_img, cmap='bone')  # Overlay GT on FLAIR\n        #axes[2].imshow(black_bg, cmap='gray', vmin=0, vmax=1)\n        axes[2].imshow(np.ma.masked_where(gt_mask_WT == 0, gt_mask_WT), cmap='cool_r', alpha=1.0)\n        axes[2].imshow(np.ma.masked_where(gt_mask_TC == 0, gt_mask_TC), cmap='autumn_r', alpha=1.0)\n        axes[2].imshow(np.ma.masked_where(gt_mask_ET == 0, gt_mask_ET), cmap='autumn', alpha=1.0)\n\n        # Prediction Segmentation\n        axes[3].set_title(\"Prediction\", fontsize=14, weight='bold')\n        axes[3].imshow(flair_img, cmap='bone')  # Overlay Prediction on FLAIR\n        axes[3].imshow(np.ma.masked_where(pr_mask_WT == 0, pr_mask_WT), cmap='cool_r', alpha=1.0)\n        axes[3].imshow(np.ma.masked_where(pr_mask_TC == 0, pr_mask_TC), cmap='autumn_r', alpha=1.0)\n        axes[3].imshow(np.ma.masked_where(pr_mask_ET == 0, pr_mask_ET), cmap='autumn', alpha=1.0)\n\n        plt.tight_layout()\n        plt.show()\n\n# Initialize with the desired slice index (e.g., 64)\nshow_result = ShowResult(slice_idx=64)\n\n# Iterate through results and plot\nfor id_, img, gt, prediction in zip(external_results['Id'], external_results['image'], external_results['GT'], external_results['Prediction']):\n    print(f\"Displaying results for ID: {id_}\")\n    show_result.plot(img, gt, prediction)","metadata":{"_uuid":"eba1b528-7558-4a39-b091-d1c948eff8cf","_cell_guid":"8f72f5e1-e3d3-4dc8-9284-cc41a48fc2a9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}